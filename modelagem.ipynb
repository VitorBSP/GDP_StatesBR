{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from skopt import dummy_minimize, gp_minimize\n",
    "from sklearn import preprocessing\n",
    "from utils.functions import *\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\"./data/data_modelagem.csv\")\n",
    "base = base.drop(columns=['State', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(base['Region'])\n",
    "base[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.drop(columns=['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = base.iloc[0:27, :].drop(columns=['territorialidade'])\n",
    "teste = base.iloc[27:54, :].drop(columns=['territorialidade'])\n",
    "val = base.iloc[54:81, :].drop(columns=['territorialidade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino = treino['renda_per_capita_']\n",
    "y_teste = teste['renda_per_capita_']\n",
    "y_val = val['renda_per_capita_']\n",
    "treino = treino.drop(columns=['renda_per_capita_'])\n",
    "teste = teste.drop(columns=['renda_per_capita_'])\n",
    "val = val.drop(columns=['renda_per_capita_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_space(model):\n",
    "    model = model.lower()\n",
    "    space = {}\n",
    "    if model == 'dt':\n",
    "        space = {\n",
    "            'min_samples_leaf': hp.randint('min_samples_leaf', 1,50),\n",
    "            'max_depth': hp.randint('max_depth', 1,25),\n",
    "            'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2']),\n",
    "            'min_impurity_decrease': hp.uniform('min_impurity_decrease', 0, 1)\n",
    "            }\n",
    "    elif model == 'lasso':\n",
    "        space = {\n",
    "            'alpha' : hp.uniform('alpha', 0.00001, 10),\n",
    "            'warm_start' : hp.choice('warm_start', [True, False]),\n",
    "            'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
    "            'max_iter' : hp.choice('max_iter', range(100,1000))\n",
    "            }\n",
    "    elif model == 'ridge':\n",
    "        space = {\n",
    "            'alpha' : hp.uniform('alpha', 0.00001, 500),\n",
    "            'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
    "            'max_iter' : hp.choice('max_iter', range(100,1000)),\n",
    "            'solver' : hp.choice('solver', ['svd', 'sag', 'saga', 'lbfgs', 'auto']),\n",
    "            }\n",
    "    elif model == 'linear':\n",
    "         space = {\n",
    "            'fit_intercept' : hp.choice('fit_intercept', [True, False]),\n",
    "            }\n",
    "    elif model == 'elastic':\n",
    "        space = {\n",
    "            'alpha' : hp.uniform('alpha', 0.00001, 100),\n",
    "            'l1_ratio' : hp.uniform('l1_ratio', 0, 1),\n",
    "            'warm_start' : hp.choice('warm_start', [True, False]),\n",
    "            'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
    "            'max_iter' : hp.choice('max_iter', range(100,1000)),\n",
    "            }\n",
    "    elif model == 'rf':\n",
    "        space = {\n",
    "                'min_samples_leaf': hp.randint('min_samples_leaf', 1,50),\n",
    "                'max_depth': hp.randint('max_depth', 1,20),\n",
    "                'n_estimators': hp.randint('n_estimators', 50,1000),\n",
    "                'max_leaf_nodes' : hp.randint('max_leaf_nodes', 2,100),\n",
    "                'min_impurity_decrease': hp.uniform('min_impurity_decrease', 0.0, 0.3)\n",
    "            }\n",
    "    elif model == 'lgbm':\n",
    "        space = {\n",
    "            'num_leaves':  hp.randint('num_leaves', 1,50),\n",
    "            'max_depth': hp.randint('max_depth', 1,20),\n",
    "            'feature_fraction':  hp.uniform('feature_fraction', 0.2, 0.5),\n",
    "            'subsample':  hp.uniform('subsample', 0.2, 1),\n",
    "            'bagging_fraction':  hp.uniform('bagging_fraction', 0.5, 0.9),    \n",
    "            'learning_rate':  hp.uniform('learning_rate', 0.001, 0.1),\n",
    "            'lambda_l1':  hp.uniform('lambda_l1', 0.0001, 1),\n",
    "            'lambda_l2':  hp.uniform('lambda_l2', 0.0001, 1),\n",
    "            'min_child_samples': hp.randint('min_child_samples', 1,50),\n",
    "            'n_estimators': hp.randint('n_estimators', 50,1000),\n",
    "            'colsample_bytree':  hp.uniform('colsample_bytree', 0.1, 1)  \n",
    "            }\n",
    "    elif model == 'xgb':\n",
    "        space={\n",
    "                'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "                'learning_rate':  hp.uniform('learning_rate', 0.001, 0.1),\n",
    "                'gamma': hp.uniform ('gamma', 1,9),\n",
    "                'min_child_samples': hp.choice('min_child_samples', range(1,50)),\n",
    "                'subsample':  hp.uniform('subsample', 0.2, 1),\n",
    "                'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "                'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "                'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "                'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "                'n_estimators': hp.choice('n_estimators', range(50,1000)),\n",
    "                'parallel_tree': hp.uniform ('parallel_tree', 1,10),\n",
    "            }\n",
    "    space['model'] = model\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "            'dt' : DecisionTreeRegressor,\n",
    "            'rf' : RandomForestRegressor,\n",
    "            'xgb' : XGBRegressor,\n",
    "            'lgbm' : LGBMRegressor ,\n",
    "            'lasso' : Lasso,\n",
    "            'elastic' : ElasticNet,\n",
    "            'ridge' : Ridge,\n",
    "            'linear' : LinearRegression\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_status(clf,X_,y):\n",
    "    acc = cross_val_score(clf, X_, y, cv=5, scoring=\"neg_root_mean_squared_error\").mean()\n",
    "    display(clear=True)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def obj_fnc(params):\n",
    "    print(type(params.get('model')), '---')\n",
    "    model = params.get('model').lower()\n",
    "    del params['model']\n",
    "    clf = models[model](**params)\n",
    "    display(clear=True)\n",
    "    return(get_acc_status(clf,treino,y_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': {}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:17<00:00,  3.95s/trial, best loss: 130.25232044147418]\n",
      "{}\n",
      "130.25232044147418\n"
     ]
    }
   ],
   "source": [
    "best_params = {}\n",
    "hypopt_trials = {}\n",
    "\n",
    "for model in models:\n",
    "    hypopt_trials[model] = Trials()\n",
    "    best_params[model] = fmin(obj_fnc, search_space(model), algo=tpe.suggest,\n",
    "    max_evals=50, trials= hypopt_trials[model])\n",
    "    print(best_params[model])\n",
    "    print(hypopt_trials[model].best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:12:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"min_child_samples\", \"parallel_tree\" } are not used.\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.33287604242037755, colsample_bytree=0.6048991907090416 will be ignored. Current value: feature_fraction=0.33287604242037755\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4262902103134426, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4262902103134426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5079375723782639, subsample=0.8770485104249668 will be ignored. Current value: bagging_fraction=0.5079375723782639\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28306287416779663, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28306287416779663\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aluga.com\\repos\\GDP_StatesBR\\modelagem.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39melif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     bootstrap \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mBayesian\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mBernoulli\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     trainedcat \u001b[39m=\u001b[39m CatBoostRegressor(learning_rate \u001b[39m=\u001b[39m best_params[model][\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m                                         iterations \u001b[39m=\u001b[39m best_params[model][\u001b[39m'\u001b[39m\u001b[39miterations\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m                                         l2_leaf_reg \u001b[39m=\u001b[39m best_params[model][\u001b[39m'\u001b[39m\u001b[39ml2_leaf_reg\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m                                         depth \u001b[39m=\u001b[39m best_params[model][\u001b[39m'\u001b[39m\u001b[39mdepth\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m                                         colsample_bylevel \u001b[39m=\u001b[39m best_params[model][\u001b[39m'\u001b[39m\u001b[39mcolsample_bylevel\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m                                         bootstrap_type \u001b[39m=\u001b[39m bootstrap[best_params[model][\u001b[39m'\u001b[39m\u001b[39mbootstrap_type\u001b[39m\u001b[39m'\u001b[39m]] \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aluga.com/repos/GDP_StatesBR/modelagem.ipynb#X60sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m                                         )\u001b[39m.\u001b[39mfit(treino, y_treino)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'learning_rate'"
     ]
    }
   ],
   "source": [
    "for model in best_params:\n",
    "    if model == 'rf':\n",
    "        crit = {0: 'gini', 1:  'entropy', 2: 'log_loss'}\n",
    "        feat = {0: 'sqrt', 1: 'log2', 2: None}\n",
    "\n",
    "        trainedforest = RandomForestRegressor(\n",
    "                                            min_samples_leaf = best_params[model]['min_samples_leaf'], \n",
    "                                            max_depth = best_params[model]['max_depth'], \n",
    "                                            min_impurity_decrease = best_params[model]['min_impurity_decrease'], \n",
    "                                            max_leaf_nodes = best_params[model]['max_leaf_nodes'], \n",
    "                                            n_estimators = best_params[model]['n_estimators']\n",
    "                                            ).fit(treino, y_treino)\n",
    "\n",
    "    elif model == 'xgb':\n",
    "         trainedxgb = XGBRegressor(learning_rate = best_params[model]['learning_rate'], \n",
    "                                            max_depth = best_params[model]['max_depth'], \n",
    "                                            gamma = best_params[model]['gamma'],\n",
    "                                            min_child_samples = best_params[model]['min_child_samples'],\n",
    "                                            subsample = best_params[model]['subsample'], \n",
    "                                            reg_alpha = best_params[model]['reg_alpha'],\n",
    "                                            reg_lambda = best_params[model]['reg_lambda'],\n",
    "                                            colsample_bytree = best_params[model]['colsample_bytree'], \n",
    "                                            min_child_weight = best_params[model]['min_child_weight'], \n",
    "                                            parallel_tree = best_params[model]['parallel_tree'], \n",
    "                                            n_estimators = best_params[model]['n_estimators']\n",
    "                                            ).fit(treino, y_treino)\n",
    "    elif model == 'lgbm':\n",
    "         trainedlgbm = LGBMRegressor(learning_rate = best_params[model]['learning_rate'], \n",
    "                                            max_depth = best_params[model]['max_depth'], \n",
    "                                            num_leaves = best_params[model]['num_leaves'],\n",
    "                                            subsample = best_params[model]['subsample'], \n",
    "                                            colsample_bytree = best_params[model]['colsample_bytree'], \n",
    "                                            feature_fraction = best_params[model]['feature_fraction'], \n",
    "                                            bagging_fraction = best_params[model]['bagging_fraction'], \n",
    "                                            n_estimators = best_params[model]['n_estimators'],\n",
    "                                            lambda_l1 = best_params[model]['lambda_l1'],\n",
    "                                            lambda_l2 = best_params[model]['lambda_l2'],\n",
    "                                            min_child_samples = best_params[model]['min_child_samples']\n",
    "                                            ).fit(treino, y_treino)\n",
    "\n",
    "    elif model == 'dt':\n",
    "        feat = {0: 'sqrt', 1: 'log2', 2: None}\n",
    "        trainedtree = DecisionTreeRegressor(\n",
    "                                            max_depth = best_params[model]['max_depth'], \n",
    "                                            max_features = feat[best_params[model]['max_features']], \n",
    "                                            min_samples_leaf = best_params[model]['min_samples_leaf'], \n",
    "                                            min_impurity_decrease = best_params[model]['min_impurity_decrease']).fit(treino, y_treino)\n",
    "    elif model == 'lasso':\n",
    "        booleano = {0 : True, 1 : False}\n",
    "\n",
    "        trainedlasso = Lasso(\n",
    "                                            alpha=best_params[model]['alpha'],\n",
    "                                            warm_start = booleano[best_params[model]['warm_start']],\n",
    "                                            tol = best_params[model]['tol'],\n",
    "                                            max_iter = best_params[model]['max_iter']).fit(treino, y_treino)\n",
    "    elif model == 'ridge':\n",
    "        booleano = {0 : True, 1 : False}\n",
    "        solver = {0: 'svd', 1: 'sag', 2: 'saga', 3 : 'lbfgs', 4 : 'auto'}\n",
    "        trainedridge = Ridge(\n",
    "                                            alpha=best_params[model]['alpha'],\n",
    "                                            tol = best_params[model]['tol'],\n",
    "                                            solver = solver[best_params[model]['solver']],\n",
    "                                            max_iter = best_params[model]['max_iter']).fit(treino, y_treino)\n",
    "    elif model == 'elastic':\n",
    "        booleano = {0 : True, 1 : False}\n",
    "        trainedelastic = ElasticNet(\n",
    "                                            l1_ratio=best_params[model]['l1_ratio'],\n",
    "                                            alpha=best_params[model]['alpha'],\n",
    "                                            warm_start = booleano[best_params[model]['warm_start']],\n",
    "                                            tol = best_params[model]['tol'],\n",
    "                                            max_iter = best_params[model]['max_iter']).fit(treino, y_treino)\n",
    "    elif model == 'linear':\n",
    "        booleano = {0 : True, 1 : False}\n",
    "        trainedlinear = LinearRegression(fit_intercept = booleano[best_params[model]['fit_intercept']]).fit(treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    y_pred = model.predict(val)\n",
    "    print(\"R^2 : \", r2_score(y_val, y_pred))\n",
    "    print(\"MAE :\", mean_absolute_error(y_val,y_pred))\n",
    "    print(\"RMSE:\",np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.5954617856294094\n",
      "MAE : 103.84295720222131\n",
      "RMSE: 143.20055668372154\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedlinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.6643136059104247\n",
      "MAE : 92.5285444908045\n",
      "RMSE: 130.44631019831547\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedelastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.6700565979083167\n",
      "MAE : 91.56417481213253\n",
      "RMSE: 129.32564520202732\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.7134081382699871\n",
      "MAE : 86.3072073833568\n",
      "RMSE: 120.53047179649089\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedlasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.7885442137597848\n",
      "MAE : 58.61654233579283\n",
      "RMSE: 103.53202689792998\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.7082786181232166\n",
      "MAE : 69.3034825452186\n",
      "RMSE: 121.60433602004741\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.8473010423567163\n",
      "MAE : 60.79246264577321\n",
      "RMSE: 87.97979909774462\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedlgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.6453746811154006\n",
      "MAE : 89.08342857142856\n",
      "RMSE: 134.07561550065344\n"
     ]
    }
   ],
   "source": [
    "run_experiment(trainedtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "selector = SelectKBest(score_func=f_regression, k=treino.shape[1])\n",
    "selector.fit(treino, y_treino)\n",
    "a = pd.DataFrame({'variables' : treino.columns, 'pvalues' : selector.pvalues_, 'lgbm' : trainedlgbm.feature_importances_, 'xgb' : trainedxgb.feature_importances_})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "802a45e6ea1001ee05ac0fd63f937ec92fbe9ea23ac5247270696386f141362b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
